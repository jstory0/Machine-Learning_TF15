{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03970daf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn의 결과 : 합격여부 : [1], 확률 : [[0.43740782 0.56259218]]\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_76432\\180808686.py:89: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_76432\\180808686.py:105: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_76432\\180808686.py:108: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_76432\\180808686.py:109: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "loss의 값 : 1.3669615983963013\n",
      "loss의 값 : 0.6717689633369446\n",
      "loss의 값 : 0.6183386445045471\n",
      "loss의 값 : 0.611027181148529\n",
      "loss의 값 : 0.6072802543640137\n",
      "loss의 값 : 0.6041977405548096\n",
      "loss의 값 : 0.6015024185180664\n",
      "loss의 값 : 0.5991346836090088\n",
      "loss의 값 : 0.5970442891120911\n",
      "loss의 값 : 0.5951951742172241\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model   # sklearn으로 logistic 구현\n",
    "from sklearn.preprocessing import MinMaxScaler   # 정규화 진행\n",
    "from scipy import stats   # 이상치 처리\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 경고메시지 출력하지 않음!\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('../data/admission.csv')\n",
    "\n",
    "#############################\n",
    "# preprocessing\n",
    "#############################\n",
    "\n",
    "# 결측치부터 살펴봐야 한다!\n",
    "# print(df.isnull().sum())   # 결치값은 없다!\n",
    "# df.info()\n",
    "\n",
    "# 이상치가 있는지를 확인하고 처리해보자!\n",
    "# 종속변수의 이상치를 outlier\n",
    "# 독립변수의 이상치를 지대값\n",
    "# 이상치가 존재하는지를 눈으로 확인하는 가장 쉬운 방법은 boxplot\n",
    "# figure = plt.figure()\n",
    "# ax1 = figure.add_subplot(1,4,1)\n",
    "# ax2 = figure.add_subplot(1,4,2)\n",
    "# ax3 = figure.add_subplot(1,4,3)\n",
    "# ax4 = figure.add_subplot(1,4,4)\n",
    "# ax1.set_title('ADMIT')\n",
    "# ax2.set_title('GRE')\n",
    "# ax3.set_title('GPA')\n",
    "# ax4.set_title('RANK')\n",
    "\n",
    "# ax1.boxplot(df['admit'])\n",
    "# ax2.boxplot(df['gre'])\n",
    "# ax3.boxplot(df['gpa'])\n",
    "# ax4.boxplot(df['rank'])\n",
    "\n",
    "# figure.tight_layout()\n",
    "# plt.show()\n",
    "# boxplot을 이용해서 눈으로 확인해보니 이상치가 존재한다!\n",
    "# z-score를 이용해서 이상치를 제거하고 진행해보자!\n",
    "\n",
    "zscore_threshold = 2.0\n",
    "\n",
    "for col in df.columns:\n",
    "    outlier = df[col][np.abs(stats.zscore(df[col])) > zscore_threshold]\n",
    "    df = df.loc[~df[col].isin(outlier)]\n",
    "    \n",
    "# 이상치를 제거했으니 정규화를 진행\n",
    "# display(df.head())\n",
    "x_data = df.drop('admit', axis=1, inplace=False)\n",
    "t_data = df['admit'].values.reshape(-1,1)\n",
    "# t_data는 0과 1로만 구성되어 있다. 따라서 정규화를 할 필요가 없다.\n",
    "\n",
    "# 정규화를 하기 위해 scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "\n",
    "norm_x_data = scaler.transform(x_data)\n",
    "# print(norm_x_data)\n",
    "\n",
    "# training data set\n",
    "# norm_x_data\n",
    "# t_data\n",
    "\n",
    "### sklearn 구현\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "model.fit(x_data, t_data)\n",
    "\n",
    "my_score = np.array([[600, 3.8, 1]])\n",
    "predict_val = model.predict(my_score)           # 0 or 1로 결과 도출\n",
    "predict_proba = model.predict_proba(my_score)   # 확률값으로 결과를 도출\n",
    "\n",
    "print('sklearn의 결과 : 합격여부 : {}, 확률 : {}'.format(predict_val,\n",
    "                                                         predict_proba))\n",
    "\n",
    "###############################\n",
    "# tensorflow 구현\n",
    "\n",
    "# training data set\n",
    "# norm_x_data\n",
    "# t_data\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([3,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, logistic regression model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function, cross entropy, log loss라고 하기도 한다.\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복학습\n",
    "for step in range(300000):\n",
    "    _, loss_val = sess.run([train, loss],\n",
    "                           feed_dict={X: norm_x_data,\n",
    "                                      T: t_data})\n",
    "    \n",
    "    if step % 30000 == 0:\n",
    "        print('loss의 값 : {}'.format(loss_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8800af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow로 예측한 결과 : [[0.45585647]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "my_score = np.array([[600, 3.8, 1]])\n",
    "norm_my_score = scaler.transform(my_score)\n",
    "\n",
    "result = sess.run(H, feed_dict={X: norm_my_score})\n",
    "print('tensorflow로 예측한 결과 : {}'.format(result))   # [[0.45585647]]\n",
    "# tensorflow로 예측한 결과는 탈락!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "584d85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression의 Metrics를 알아보자!\n",
    "\n",
    "### 예제는 Ozone을 이용해서 Model을 만들어보자!\n",
    "### model은 sklearn으로 구현해보자!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터셋을 train, test(validation)로 나눠준다.\n",
    "\n",
    "\n",
    "### Raw Data Loading\n",
    "df = pd.read_csv('../data/ozone.csv')\n",
    "# print(df.shape)   # (153, 6)\n",
    "\n",
    "# 결측치부터 제거\n",
    "training_data = df.dropna(how='any', inplace=False)\n",
    "# print(training_data.shape)   # (111, 6)\n",
    "\n",
    "# 이상치도 제거\n",
    "zscore_threshold = 2.0\n",
    "\n",
    "for col in training_data.columns:\n",
    "    outlier = training_data[col][np.abs(stats.zscore(training_data[col])) > zscore_threshold]\n",
    "    training_data = training_data.loc[~training_data[col].isin(outlier)]\n",
    "    \n",
    "# sklearn으로 구현할거라서 정규화 처리는 하지 않는다!\n",
    "# display(training_data.head())\n",
    "\n",
    "# Data Set\n",
    "x_data = training_data[['Solar.R', 'Wind', 'Temp']].values\n",
    "t_data = training_data['Ozone'].values.reshape(-1,1)\n",
    "\n",
    "# Train / Validation Data Set\n",
    "train_x_data, valid_x_data, train_t_data, valid_t_data = \\\n",
    "train_test_split(x_data,\n",
    "                 t_data,\n",
    "                 test_size=0.3,\n",
    "                 random_state=2)   # random의 seed 역할\n",
    "\n",
    "# Model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Model 학습\n",
    "model.fit(train_x_data, train_t_data)\n",
    "\n",
    "# 예측값(predict_value)\n",
    "# 정답(valid_t_data)\n",
    "predict_value = model.predict(valid_x_data)\n",
    "\n",
    "# 예측값과 정답간의 차이가 작으면 작을수록 좋은 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7abe202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.924465776324642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(mean_absolute_error(valid_t_data, predict_value))   # 13.924465776324642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d57bd572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271.5671192367061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(mean_squared_error(valid_t_data, predict_value))   # 271.5671192367061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1c6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3734728354920861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(r2_score(valid_t_data, predict_value))   # 0.3734728354920861"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF15] *",
   "language": "python",
   "name": "conda-env-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
