{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification의 대표적인 2개의 문제를 한번 구현해보자!\n",
    "# 1. 위스콘신 유방암 데이터\n",
    "# 2. Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c2f2297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92982456 0.93859649 0.96491228 0.95614035 0.95575221]\n",
      "0.9490451793199813\n",
      "0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 위스콘신 유방암 데이터를 가지고 구현해보자!\n",
    "# 이 데이터는 sklearn이 제공하는 데이터를 사용할 것이다!\n",
    "# sklearn과 tensorflow를 이용해서 구현해보자!\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model   # LogisticRegression()\n",
    "from sklearn.datasets import load_breast_cancer  # 데이터 로딩하기 위한 함수\n",
    "from sklearn.model_selection import train_test_split  # 학습데이터와 평가데이터 분리\n",
    "from sklearn.model_selection import cross_val_score  # cross validation하기 위해 필요!\n",
    "\n",
    "# Raw Data Loading\n",
    "cancer = load_breast_cancer()\n",
    "# print(type(cancer))   # <class 'sklearn.utils.Bunch'>\n",
    "                      # sklearn이 데이터를 표현하기 위해 사용하는 자료구조\n",
    "                      # python의 dictionary와 유사한 구조.\n",
    "# print(cancer)\n",
    "# data라는 속성과 target이라는 속성을 가지고 있고\n",
    "# data라는 속성이 독립변수, target이 종속변수\n",
    "# print(cancer.data.shape, cancer.target.shape)   # (569, 30) (569,)\n",
    "\n",
    "# print(np.unique(cancer.target, return_counts=True))\n",
    "# (array([0, 1]), array([212, 357])\n",
    "# print(cancer.DESCR)  # 유방암 데이터에 대한 상세 내용!\n",
    "# :Missing Attribute Values: None\n",
    "# :Class Distribution: 212 - Malignant(악성), 357 - Benign(정상)\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "# print(type(x_data), x_data.shape)\n",
    "# print(type(t_data), t_data.shape)\n",
    "\n",
    "# Hold-out validation을 위해서 train과 validation 데이터를 분리\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data,\n",
    "                 t_data,\n",
    "                 test_size=0.2,   # default = 0.25\n",
    "                 random_state=2,\n",
    "                 stratify=t_data)   # t_data의 class 비율대로 나누겠다!\n",
    "# print(train_x_data.shape, train_t_data.shape)   # (455, 30) (455,)\n",
    "# print(np.unique(train_t_data, return_counts=True))\n",
    "# (array([0, 1]), array([170, 285])\n",
    "\n",
    "# Model 생성\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# K-Fold cross validation\n",
    "test_score = cross_val_score(model, x_data, t_data, scoring='accuracy', cv=5)\n",
    "print(test_score)   # [0.92982456 0.93859649 0.96491228 0.95614035 0.95575221]\n",
    "print(test_score.mean())   # 0.9490451793199813\n",
    "\n",
    "# Hold-out 방식으로 validation\n",
    "model.fit(train_x_data, train_t_data)\n",
    "test_score = model.score(test_x_data, test_t_data)\n",
    "print(test_score)   # 0.956140350877193\n",
    "\n",
    "# sklearn으로 구현해보았다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1a225a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_98732\\319316690.py:6: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shcho\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_98732\\319316690.py:22: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_98732\\319316690.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_98732\\319316690.py:26: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "loss value : 162.29702758789062\n",
      "loss value : 0.8885084986686707\n",
      "loss value : 0.683427631855011\n",
      "loss value : 0.5494958758354187\n",
      "loss value : 0.4655437469482422\n",
      "loss value : 0.4264872372150421\n",
      "loss value : 0.40537554025650024\n",
      "loss value : 0.1832481473684311\n",
      "loss value : 0.18105252087116241\n",
      "loss value : 0.1833561658859253\n"
     ]
    }
   ],
   "source": [
    "# 위의 데이터를 이용해서 이번에는 Tensorflow를 이용해 구현해보자!\n",
    "import tensorflow as tf\n",
    "## tensorflow 그래프를 그려보자!\n",
    "\n",
    "## placeholder\n",
    "X = tf.placeholder(shape=[None, 30], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([30,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, Logistic Regression Model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cross entropy(loss function)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())   # 초기화 작업.\n",
    "\n",
    "# 반복학습\n",
    "# 전체 데이터를 이용해서 1번 학습 => 1 epoch(에폭)\n",
    "for step in range(100000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X: train_x_data,\n",
    "                                                     T: train_t_data.reshape(-1,1)})\n",
    "    if step % 10000 == 0:\n",
    "        print('loss value : {}'.format(loss_val))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3ba577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9385964870452881\n"
     ]
    }
   ],
   "source": [
    "# 정확도(accuracy) 측정\n",
    "\n",
    "# validation data(test_x_data, test_t_data)를 이용해서 정확도를 측정\n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32)   # True -> 1.0\n",
    "                                                # False -> 0.0\n",
    "correct = tf.equal(predict, T)     # True, False, False, True, ...\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32)) # 1, 0, 0, 1\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data,\n",
    "                                             T: test_t_data.reshape(-1,1)})\n",
    "print('Accuracy : {}'.format(accuracy_val))   # 0.9385964870452881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77619e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 titanic 예제를 이용해서 Logistic Regression을 구현해보자!\n",
    "# Kaggle에서 데이터셋을 받아서 나온 결과를 Kaggle에 upload해서 우리 모델의\n",
    "# 정확도를 평가받아보자!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF15] *",
   "language": "python",
   "name": "conda-env-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
